{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Neural Network for Time Series Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from: http://www.jakob-aungiers.com/articles/a/LSTM-Neural-Network-for-Time-Series-Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Plot the data to learn from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is provided by Jakob to be downloaded from <a href=\"https://raw.githubusercontent.com/jaungiers/LSTM-Neural-Network-for-Time-Series-Prediction/master/sinwave.csv\"> here </a>, the graph should look like the one shown below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.jakob-aungiers.com/img/article/lstm-neural-network-timeseries/sindata.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to load and plot is also provided: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(filename, seq_len, normalise_window):\n",
    "    f = open(filename, 'rb').read()\n",
    "    data = f.decode().split('\\n')\n",
    "\n",
    "    sequence_length = seq_len + 1\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "\n",
    "    result = np.array(result)\n",
    "\n",
    "    row = round(0.9 * result.shape[0])\n",
    "    train = result[:int(row), :]\n",
    "    np.random.shuffle(train)\n",
    "    x_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    x_test = result[int(row):, :-1]\n",
    "    y_test = result[int(row):, -1]\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))  \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Analysing the load and plot function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_data = 'sinwave.csv'\n",
    "\n",
    "\n",
    "f = open(path_data, 'rb').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/f_info.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 What does f.decode() ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.1.1 Example from: https://www.tutorialspoint.com/python/string_decode.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "'base64' is not a text encoding; use codecs.encode() to handle arbitrary codecs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8b2d918afdd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mStr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"this is string example....wow!!!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mStr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'base64'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Encoded String: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mStr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Decoded String: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mStr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'base64'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#pendiente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: 'base64' is not a text encoding; use codecs.encode() to handle arbitrary codecs"
     ]
    }
   ],
   "source": [
    "Str = \"this is string example....wow!!!\"\n",
    "Str = Str.encode('base64','strict')\n",
    "\n",
    "print(\"Encoded String: \" + Str)\n",
    "print(\"Decoded String: \" + Str.decode('base64','strict')) #pendiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return to: 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_data = 'sinwave.csv'\n",
    "\n",
    "f = open(path_data, 'rb').read()\n",
    "data = f.decode().split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 50\n",
    "sequence_length = seq_len + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for index in range(len(data) - sequence_length):\n",
    "    result.append(data[index: index + sequence_length])\n",
    "\n",
    "result = np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "[ 2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "[ 3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "[ 5  6  7  8  9 10 11 12 13 14 15 16 17]\n",
      "[ 6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "[ 7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21]\n",
      "[10 11 12 13 14 15 16 17 18 19 20 21 22]\n",
      "[11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "[12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "[13 14 15 16 17 18 19 20 21 22 23 24 25]\n",
      "[14 15 16 17 18 19 20 21 22 23 24 25 26]\n",
      "[15 16 17 18 19 20 21 22 23 24 25 26 27]\n",
      "[16 17 18 19 20 21 22 23 24 25 26 27 28]\n",
      "[17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "[18 19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[19 20 21 22 23 24 25 26 27 28 29 30 31]\n",
      "[20 21 22 23 24 25 26 27 28 29 30 31 32]\n",
      "[21 22 23 24 25 26 27 28 29 30 31 32 33]\n",
      "[22 23 24 25 26 27 28 29 30 31 32 33 34]\n",
      "[23 24 25 26 27 28 29 30 31 32 33 34 35]\n",
      "[24 25 26 27 28 29 30 31 32 33 34 35 36]\n",
      "[25 26 27 28 29 30 31 32 33 34 35 36 37]\n",
      "[26 27 28 29 30 31 32 33 34 35 36 37 38]\n",
      "[27 28 29 30 31 32 33 34 35 36 37 38 39]\n",
      "[28 29 30 31 32 33 34 35 36 37 38 39 40]\n",
      "[29 30 31 32 33 34 35 36 37 38 39 40 41]\n",
      "[30 31 32 33 34 35 36 37 38 39 40 41 42]\n",
      "[31 32 33 34 35 36 37 38 39 40 41 42 43]\n",
      "[32 33 34 35 36 37 38 39 40 41 42 43 44]\n",
      "[33 34 35 36 37 38 39 40 41 42 43 44 45]\n",
      "[34 35 36 37 38 39 40 41 42 43 44 45 46]\n",
      "[35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "[36 37 38 39 40 41 42 43 44 45 46 47 48]\n",
      "[37 38 39 40 41 42 43 44 45 46 47 48 49]\n",
      "[38 39 40 41 42 43 44 45 46 47 48 49 50]\n",
      "[39 40 41 42 43 44 45 46 47 48 49 50 51]\n",
      "[40 41 42 43 44 45 46 47 48 49 50 51 52]\n",
      "[41 42 43 44 45 46 47 48 49 50 51 52 53]\n",
      "[42 43 44 45 46 47 48 49 50 51 52 53 54]\n",
      "[43 44 45 46 47 48 49 50 51 52 53 54 55]\n",
      "[44 45 46 47 48 49 50 51 52 53 54 55 56]\n",
      "[45 46 47 48 49 50 51 52 53 54 55 56 57]\n",
      "[46 47 48 49 50 51 52 53 54 55 56 57 58]\n",
      "[47 48 49 50 51 52 53 54 55 56 57 58 59]\n",
      "[48 49 50 51 52 53 54 55 56 57 58 59 60]\n",
      "[49 50 51 52 53 54 55 56 57 58 59 60 61]\n",
      "[50 51 52 53 54 55 56 57 58 59 60 61 62]\n",
      "[51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "[52 53 54 55 56 57 58 59 60 61 62 63 64]\n",
      "[53 54 55 56 57 58 59 60 61 62 63 64 65]\n",
      "[54 55 56 57 58 59 60 61 62 63 64 65 66]\n",
      "[55 56 57 58 59 60 61 62 63 64 65 66 67]\n",
      "[56 57 58 59 60 61 62 63 64 65 66 67 68]\n",
      "[57 58 59 60 61 62 63 64 65 66 67 68 69]\n",
      "[58 59 60 61 62 63 64 65 66 67 68 69 70]\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.arange(1, 72)\n",
    "print(data.shape[0])\n",
    "seq_len = 12\n",
    "sequence_length = seq_len + 1\n",
    "\n",
    "result = []\n",
    "for index in range(len(data) - sequence_length):\n",
    "    _ = data[index:index + sequence_length]\n",
    "    result.append(_)\n",
    "    print(_)\n",
    "    \n",
    "print(len(result))\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "58 - 71"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i'll do it like the tutorial, but in these cases, i would think that the data should be something like: [1, 2, 3, 4], [ 4, 5, 6, 7],  [8, 9, 10, 11].. and so on for a window of size=4 elements for example, (i need to read the theory behind lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "[13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "[25 26 27 28 29 30 31 32 33 34 35 36]\n",
      "[37 38 39 40 41 42 43 44 45 46 47 48]\n",
      "[49 50 51 52 53 54 55 56 57 58 59 60]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.arange(1, 72)\n",
    "print(data.shape[0])\n",
    "seq_len = 12\n",
    "sequence_length = seq_len + 1\n",
    "\n",
    "size_window = 12\n",
    "index_arr = np.arange(0, len(data) - size_window, size_window)\n",
    "\n",
    "result = []\n",
    "for index in index_arr:\n",
    "    _ = data[index:(index + size_window)]\n",
    "    result.append(_)\n",
    "    print(_)\n",
    "    \n",
    "print(len(result))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "[1 2 3 4]\n",
      "[5 6 7 8]\n",
      "[ 9 10 11 12]\n",
      "[13 14 15 16]\n",
      "[17 18 19 20]\n",
      "[21 22 23 24]\n",
      "[25 26 27 28]\n",
      "[29 30 31 32]\n",
      "[33 34 35 36]\n",
      "[37 38 39 40]\n",
      "[41 42 43 44]\n",
      "[45 46 47 48]\n",
      "[49 50 51 52]\n",
      "[53 54 55 56]\n",
      "[57 58 59 60]\n",
      "[61 62 63 64]\n",
      "[65 66 67 68]\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.arange(1, 72)\n",
    "print(data.shape[0])\n",
    "seq_len = 12\n",
    "sequence_length = seq_len + 1\n",
    "\n",
    "size_window = 4\n",
    "index_arr = np.arange(0, len(data) - size_window, size_window)\n",
    "\n",
    "result = []\n",
    "for index in index_arr:\n",
    "    _ = data[index:(index + size_window)]\n",
    "    result.append(_)\n",
    "    print(_)\n",
    "    \n",
    "print(len(result))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "path_data = 'sinwave.csv'\n",
    "\n",
    "f = open(path_data, 'rb').read()\n",
    "data = f.decode().split('\\n')\n",
    "\n",
    "seq_len = 50\n",
    "sequence_length = seq_len + 1\n",
    "\n",
    "result = []\n",
    "for index in range(len(data) - sequence_length):\n",
    "    result.append(data[index: index + sequence_length])\n",
    "\n",
    "result = np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5001\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4950, 51)\n"
     ]
    }
   ],
   "source": [
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "path_data = 'sinwave.csv'\n",
    "\n",
    "f = open(path_data, 'rb').read()\n",
    "data = f.decode().split('\\n')\n",
    "\n",
    "seq_len = 50\n",
    "sequence_length = seq_len + 1\n",
    "\n",
    "result = []\n",
    "for index in range(len(data) - sequence_length):\n",
    "    result.append(data[index: index + sequence_length])\n",
    "\n",
    "result = np.array(result)\n",
    "row = round(0.9 * result.shape[0])\n",
    "train = result[:int(row), :]\n",
    "np.random.shuffle(train)\n",
    "x_train = train[:, :-1]\n",
    "y_train = train[:, -1]\n",
    "x_test = result[int(row):, :-1]\n",
    "y_test = result[int(row):, -1]\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "path_data = 'sinwave.csv'\n",
    "\n",
    "f = open(path_data, 'rb').read()\n",
    "data = f.decode().split('\\n')\n",
    "\n",
    "seq_len = 50\n",
    "sequence_length = seq_len + 1\n",
    "\n",
    "result = []\n",
    "for index in range(len(data) - sequence_length):\n",
    "    result.append(data[index: index + sequence_length])\n",
    "\n",
    "result = np.array(result)\n",
    "\n",
    "split_porcentage = 0.9\n",
    "\n",
    "row = round(split_porcentage * result.shape[0])\n",
    "\n",
    "train = result[:int(row), :]\n",
    "np.random.shuffle(train)\n",
    "x_train = train[:, :-1]\n",
    "y_train = train[:, -1]\n",
    "x_test = result[int(row):, :-1]\n",
    "y_test = result[int(row):, -1]\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4455"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4455, 50)\n",
      "(4455, 51)\n"
     ]
    }
   ],
   "source": [
    "x_train = train[:, :-1]\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = train[:,:]\n",
    "print(x_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "path_data = 'sinwave.csv'\n",
    "\n",
    "f = open(path_data, 'rb').read()\n",
    "data = f.decode().split('\\n')\n",
    "\n",
    "seq_len = 50\n",
    "sequence_length = seq_len + 1\n",
    "\n",
    "result = []\n",
    "for index in range(len(data) - sequence_length):\n",
    "    result.append(data[index: index + sequence_length])\n",
    "\n",
    "result = np.array(result)\n",
    "\n",
    "split_porcentage = 0.9\n",
    "\n",
    "row = round(split_porcentage * result.shape[0])\n",
    "\n",
    "train = result[:int(row), :]\n",
    "np.random.shuffle(train)\n",
    "x_train = train[:, :-1]\n",
    "y_train = train[:,-1]\n",
    "x_test = result[int(row):, :-1]\n",
    "y_test = result[int(row):, -1]\n",
    "\n",
    "\n",
    "#x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "#x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4455, 50)\n",
      "(4455,)\n",
      "(495, 50)\n",
      "(495,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4455, 51)\n",
      "['0.688408006' '-0.688408006' '0.927808777' ..., '0.531336178'\n",
      " '0.983268329' '0.841470985']\n",
      "(4455,)\n",
      "['0.688408006' '-0.688408006' '0.927808777' ..., '0.531336178'\n",
      " '0.983268329' '0.841470985']\n"
     ]
    }
   ],
   "source": [
    "x_train = train[:, :]\n",
    "print(x_train.shape)\n",
    "print(x_train[:,-1])\n",
    "y_train = train[:,-1]\n",
    "print(y_train.shape)\n",
    "print(y_train)\n",
    "#x_test = result[int(row):, :-1]\n",
    "#y_test = result[int(row):, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4950, 51)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "path_data = 'sinwave.csv'\n",
    "\n",
    "f = open(path_data, 'rb').read()\n",
    "data = f.decode().split('\\n')\n",
    "\n",
    "seq_len = 50\n",
    "sequence_length = seq_len + 1\n",
    "\n",
    "result = []\n",
    "for index in range(len(data) - sequence_length):\n",
    "    result.append(data[index: index + sequence_length])\n",
    "\n",
    "result = np.array(result)\n",
    "\n",
    "split_porcentage = 0.9\n",
    "\n",
    "row = round(split_porcentage * result.shape[0])\n",
    "\n",
    "result.shape\n",
    "\n",
    "#train = result[:int(row), :]\n",
    "#np.random.shuffle(train)\n",
    "#x_train = train[:, :-1]\n",
    "#y_train = train[:,-1]\n",
    "#x_test = result[int(row):, :-1]\n",
    "#y_test = result[int(row):, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.841470985', '0.873736397', '0.90255357', ..., '-0.7671179',\n",
       "        '-0.805884672', '-0.841470985'],\n",
       "       ['0.873736397', '0.90255357', '0.927808777', ..., '-0.805884672',\n",
       "        '-0.841470985', '-0.873736397'],\n",
       "       ['0.90255357', '0.927808777', '0.949402346', ..., '-0.841470985',\n",
       "        '-0.873736397', '-0.90255357'],\n",
       "       ..., \n",
       "       ['-0.725323664', '-0.7671179', '-0.805884672', ..., '0.633323869',\n",
       "        '0.680666907', '0.725323664'],\n",
       "       ['-0.7671179', '-0.805884672', '-0.841470985', ..., '0.680666907',\n",
       "        '0.725323664', '0.7671179'],\n",
       "       ['-0.805884672', '-0.841470985', '-0.873736397', ..., '0.725323664',\n",
       "        '0.7671179', '0.805884672']],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4950,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.841470985', '0.873736397', '0.90255357', ..., '-0.725323664',\n",
       "       '-0.7671179', '-0.805884672'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "path_data = 'sinwave.csv'\n",
    "\n",
    "f = open(path_data, 'rb').read()\n",
    "data = f.decode().split('\\n')\n",
    "\n",
    "seq_len = 50\n",
    "sequence_length = seq_len + 1\n",
    "\n",
    "result = []\n",
    "for index in range(len(data) - sequence_length):\n",
    "    result.append(data[index: index + sequence_length])\n",
    "\n",
    "result = np.array(result)\n",
    "\n",
    "split_porcentage = 0.9\n",
    "\n",
    "row = round(split_porcentage * result.shape[0])\n",
    "\n",
    "train = result[:int(row), :]\n",
    "np.random.shuffle(train)\n",
    "x_train = train[:, :-1]\n",
    "y_train = train[:,-1]\n",
    "x_test = result[int(row):, :-1]\n",
    "y_test = result[int(row):, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the length of the window is 50 and the element that remains (last element) is the value that lstm must predict. \n",
    "np.random.shuffle, classify the training set with the corresponding value 'y' because it is still connected as the last train element [:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "path_data = 'sinwave.csv'\n",
    "\n",
    "f = open(path_data, 'rb').read()\n",
    "data = f.decode().split('\\n')\n",
    "\n",
    "seq_len = 50\n",
    "sequence_length = seq_len + 1\n",
    "\n",
    "result = []\n",
    "for index in range(len(data) - sequence_length):\n",
    "    result.append(data[index: index + sequence_length])\n",
    "\n",
    "result = np.array(result)\n",
    "row = round(0.9 * result.shape[0])\n",
    "train = result[:int(row), :]\n",
    "np.random.shuffle(train)\n",
    "x_train = train[:, :-1]\n",
    "y_train = train[:, -1]\n",
    "x_test = result[int(row):, :-1]\n",
    "y_test = result[int(row):, -1]\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reshape is becouse there is only one feature for the input set and one for the <br>\n",
    "output set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4455, 50, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(495, 50, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/antadlp/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_model(layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(\n",
    "        input_shape=(layers[1], layers[0]),\n",
    "        output_dim=layers[1],\n",
    "        return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "        layers[2],\n",
    "        return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(\n",
    "        output_dim=layers[3]))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    print(\"> Compilation Time : \", time.time() - start)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_point_by_point(model, data):\n",
    "    #Predict each timestep given the last sequence of true data, in effect only predicting 1 step ahead each time\n",
    "    predicted = model.predict(data)\n",
    "    predicted = np.reshape(predicted, (predicted.size,))\n",
    "    return predicted\n",
    "\n",
    "def predict_sequence_full(model, data, window_size):\n",
    "    #Shift the window by 1 new prediction each time, re-run predictions on new window\n",
    "    curr_frame = data[0]\n",
    "    predicted = []\n",
    "    for i in range(len(data)):\n",
    "        predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "        curr_frame = curr_frame[1:]\n",
    "        curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)\n",
    "    return predicted\n",
    "\n",
    "def predict_sequences_multiple(model, data, window_size, prediction_len):\n",
    "    #Predict sequence of 50 steps before shifting prediction run forward by 50 steps\n",
    "    prediction_seqs = []\n",
    "    for i in range(int(len(data)/prediction_len)):\n",
    "        curr_frame = data[i*prediction_len]\n",
    "        predicted = []\n",
    "        for j in range(prediction_len):\n",
    "            predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "            curr_frame = curr_frame[1:]\n",
    "            curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)\n",
    "        prediction_seqs.append(predicted)\n",
    "    \n",
    "    return prediction_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename, seq_len, normalise_window):\n",
    "    f = open(filename, 'rb').read()\n",
    "    data = f.decode().split('\\n')\n",
    "\n",
    "    sequence_length = seq_len + 1\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "\n",
    "    result = np.array(result)\n",
    "\n",
    "    row = round(0.9 * result.shape[0])\n",
    "    train = result[:int(row), :]\n",
    "    np.random.shuffle(train)\n",
    "    x_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    x_test = result[int(row):, :-1]\n",
    "    y_test = result[int(row):, -1]\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))  \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading data... \n",
      "> Data Loaded. Compiling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antadlp/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(input_shape=(50, 1), return_sequences=True, units=50)`\n",
      "  \n",
      "/home/antadlp/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1)`\n",
      "/home/antadlp/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Compilation Time :  0.015604019165039062\n",
      "Train on 4232 samples, validate on 223 samples\n",
      "Epoch 1/30\n",
      "4232/4232 [==============================] - 2s 449us/step - loss: 0.1571 - val_loss: 0.0607\n",
      "Epoch 2/30\n",
      "4232/4232 [==============================] - 1s 322us/step - loss: 0.0210 - val_loss: 0.0242\n",
      "Epoch 3/30\n",
      "4232/4232 [==============================] - 1s 314us/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 4/30\n",
      "4232/4232 [==============================] - 1s 309us/step - loss: 0.0159 - val_loss: 0.0038\n",
      "Epoch 5/30\n",
      "4232/4232 [==============================] - 1s 308us/step - loss: 0.0139 - val_loss: 0.0058\n",
      "Epoch 6/30\n",
      "4232/4232 [==============================] - 1s 311us/step - loss: 0.0100 - val_loss: 0.0122\n",
      "Epoch 7/30\n",
      "4232/4232 [==============================] - 1s 305us/step - loss: 0.0110 - val_loss: 0.0070\n",
      "Epoch 8/30\n",
      "4232/4232 [==============================] - 1s 314us/step - loss: 0.0123 - val_loss: 0.0066\n",
      "Epoch 9/30\n",
      "4232/4232 [==============================] - 1s 317us/step - loss: 0.0100 - val_loss: 0.0056\n",
      "Epoch 10/30\n",
      "4232/4232 [==============================] - 1s 319us/step - loss: 0.0103 - val_loss: 0.0053\n",
      "Epoch 11/30\n",
      "4232/4232 [==============================] - 1s 318us/step - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 12/30\n",
      "4232/4232 [==============================] - 1s 314us/step - loss: 0.0103 - val_loss: 0.0012\n",
      "Epoch 13/30\n",
      "4232/4232 [==============================] - 1s 314us/step - loss: 0.0077 - val_loss: 0.0098\n",
      "Epoch 14/30\n",
      "4232/4232 [==============================] - 1s 309us/step - loss: 0.0096 - val_loss: 0.0051\n",
      "Epoch 15/30\n",
      "4232/4232 [==============================] - 1s 310us/step - loss: 0.0083 - val_loss: 0.0087\n",
      "Epoch 16/30\n",
      "4232/4232 [==============================] - 1s 314us/step - loss: 0.0070 - val_loss: 0.0122\n",
      "Epoch 17/30\n",
      "4232/4232 [==============================] - 1s 306us/step - loss: 0.0086 - val_loss: 0.0020\n",
      "Epoch 18/30\n",
      "4232/4232 [==============================] - 1s 322us/step - loss: 0.0075 - val_loss: 0.0037\n",
      "Epoch 19/30\n",
      "4232/4232 [==============================] - 1s 326us/step - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 20/30\n",
      "4232/4232 [==============================] - 1s 326us/step - loss: 0.0099 - val_loss: 0.0037\n",
      "Epoch 21/30\n",
      "4232/4232 [==============================] - 1s 329us/step - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 22/30\n",
      "4232/4232 [==============================] - 1s 307us/step - loss: 0.0086 - val_loss: 0.0012\n",
      "Epoch 23/30\n",
      "4232/4232 [==============================] - 1s 309us/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 24/30\n",
      "4232/4232 [==============================] - 1s 313us/step - loss: 0.0069 - val_loss: 0.0035\n",
      "Epoch 25/30\n",
      "4232/4232 [==============================] - 1s 315us/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 26/30\n",
      "4232/4232 [==============================] - 1s 308us/step - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 27/30\n",
      "4232/4232 [==============================] - 1s 314us/step - loss: 0.0069 - val_loss: 0.0038\n",
      "Epoch 28/30\n",
      "4232/4232 [==============================] - 1s 306us/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 29/30\n",
      "4232/4232 [==============================] - 1s 309us/step - loss: 0.0062 - val_loss: 0.0040\n",
      "Epoch 30/30\n",
      "4232/4232 [==============================] - 1s 319us/step - loss: 0.0065 - val_loss: 0.0089\n"
     ]
    }
   ],
   "source": [
    "epochs  = 30\n",
    "seq_len = 50\n",
    "path_data = 'sinwave.csv'\n",
    "\n",
    "print('> Loading data... ')\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(path_data, seq_len, True)\n",
    "\n",
    "print('> Data Loaded. Compiling...')\n",
    "\n",
    "model = build_model([1, 50, 100, 1])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    nb_epoch=epochs,\n",
    "    validation_split=0.05)\n",
    "\n",
    "predicted = predict_point_by_point(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(495,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading data... \n",
      "> Data Loaded. Compiling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antadlp/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(input_shape=(50, 1), return_sequences=True, units=50)`\n",
      "  \n",
      "/home/antadlp/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1)`\n",
      "/home/antadlp/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Compilation Time :  0.026531219482421875\n",
      "Train on 4232 samples, validate on 223 samples\n",
      "Epoch 1/100\n",
      "4232/4232 [==============================] - 2s 469us/step - loss: 0.2041 - val_loss: 0.0557\n",
      "Epoch 2/100\n",
      "4232/4232 [==============================] - 1s 319us/step - loss: 0.0352 - val_loss: 0.0102\n",
      "Epoch 3/100\n",
      "4232/4232 [==============================] - 1s 309us/step - loss: 0.0149 - val_loss: 0.0039\n",
      "Epoch 4/100\n",
      "4232/4232 [==============================] - 1s 309us/step - loss: 0.0130 - val_loss: 0.0073\n",
      "Epoch 5/100\n",
      "4232/4232 [==============================] - 1s 316us/step - loss: 0.0130 - val_loss: 0.0015\n",
      "Epoch 6/100\n",
      "4232/4232 [==============================] - 1s 329us/step - loss: 0.0112 - val_loss: 0.0071\n",
      "Epoch 7/100\n",
      "4232/4232 [==============================] - 1s 321us/step - loss: 0.0102 - val_loss: 0.0062\n",
      "Epoch 8/100\n",
      "4232/4232 [==============================] - 1s 316us/step - loss: 0.0092 - val_loss: 0.0130\n",
      "Epoch 9/100\n",
      "4232/4232 [==============================] - 1s 313us/step - loss: 0.0106 - val_loss: 0.0016\n",
      "Epoch 10/100\n",
      "4232/4232 [==============================] - 1s 314us/step - loss: 0.0106 - val_loss: 0.0065\n",
      "Epoch 11/100\n",
      "4232/4232 [==============================] - 1s 327us/step - loss: 0.0076 - val_loss: 0.0011\n",
      "Epoch 12/100\n",
      "4232/4232 [==============================] - 1s 309us/step - loss: 0.0102 - val_loss: 0.0019\n",
      "Epoch 13/100\n",
      "4232/4232 [==============================] - 1s 317us/step - loss: 0.0085 - val_loss: 0.0037\n",
      "Epoch 14/100\n",
      "4232/4232 [==============================] - 1s 315us/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 15/100\n",
      "4232/4232 [==============================] - 1s 330us/step - loss: 0.0088 - val_loss: 0.0049\n",
      "Epoch 16/100\n",
      "4232/4232 [==============================] - 1s 313us/step - loss: 0.0079 - val_loss: 0.0021\n",
      "Epoch 17/100\n",
      "4232/4232 [==============================] - 1s 309us/step - loss: 0.0070 - val_loss: 0.0102\n",
      "Epoch 18/100\n",
      "4232/4232 [==============================] - 1s 313us/step - loss: 0.0074 - val_loss: 0.0021\n",
      "Epoch 19/100\n",
      "4232/4232 [==============================] - 1s 316us/step - loss: 0.0087 - val_loss: 0.0013\n",
      "Epoch 20/100\n",
      "4232/4232 [==============================] - 1s 311us/step - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 21/100\n",
      "4232/4232 [==============================] - 1s 316us/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 22/100\n",
      "4232/4232 [==============================] - 1s 308us/step - loss: 0.0076 - val_loss: 0.0017\n",
      "Epoch 23/100\n",
      "4232/4232 [==============================] - 1s 318us/step - loss: 0.0062 - val_loss: 0.0037\n",
      "Epoch 24/100\n",
      "4232/4232 [==============================] - 1s 316us/step - loss: 0.0074 - val_loss: 0.0032\n",
      "Epoch 25/100\n",
      "4232/4232 [==============================] - 1s 312us/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 26/100\n",
      "4232/4232 [==============================] - 1s 338us/step - loss: 0.0069 - val_loss: 0.0015\n",
      "Epoch 27/100\n",
      "4232/4232 [==============================] - 1s 314us/step - loss: 0.0066 - val_loss: 0.0037\n",
      "Epoch 28/100\n",
      "4232/4232 [==============================] - 1s 319us/step - loss: 0.0055 - val_loss: 0.0020\n",
      "Epoch 29/100\n",
      "4232/4232 [==============================] - 1s 318us/step - loss: 0.0073 - val_loss: 0.0010\n",
      "Epoch 30/100\n",
      "4232/4232 [==============================] - 1s 316us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 31/100\n",
      "4232/4232 [==============================] - 1s 321us/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 32/100\n",
      "4232/4232 [==============================] - 1s 318us/step - loss: 0.0065 - val_loss: 0.0025\n",
      "Epoch 33/100\n",
      "4232/4232 [==============================] - 1s 315us/step - loss: 0.0054 - val_loss: 0.0017\n",
      "Epoch 34/100\n",
      "4232/4232 [==============================] - 1s 315us/step - loss: 0.0066 - val_loss: 0.0030\n",
      "Epoch 35/100\n",
      "4232/4232 [==============================] - 1s 317us/step - loss: 0.0051 - val_loss: 6.0811e-04\n",
      "Epoch 36/100\n",
      "4232/4232 [==============================] - 1s 312us/step - loss: 0.0068 - val_loss: 0.0025\n",
      "Epoch 37/100\n",
      "4232/4232 [==============================] - 1s 315us/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 38/100\n",
      "4232/4232 [==============================] - 1s 341us/step - loss: 0.0067 - val_loss: 0.0017\n",
      "Epoch 39/100\n",
      "4232/4232 [==============================] - 1s 313us/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 40/100\n",
      "4232/4232 [==============================] - 1s 312us/step - loss: 0.0050 - val_loss: 0.0022\n",
      "Epoch 41/100\n",
      "4232/4232 [==============================] - 1s 313us/step - loss: 0.0061 - val_loss: 0.0026\n",
      "Epoch 42/100\n",
      "4232/4232 [==============================] - 1s 320us/step - loss: 0.0048 - val_loss: 0.0023\n",
      "Epoch 43/100\n",
      "4232/4232 [==============================] - 1s 318us/step - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 44/100\n",
      "4232/4232 [==============================] - 1s 317us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 45/100\n",
      "4232/4232 [==============================] - 1s 311us/step - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 46/100\n",
      "4232/4232 [==============================] - 1s 314us/step - loss: 0.0056 - val_loss: 0.0028\n",
      "Epoch 47/100\n",
      "4232/4232 [==============================] - 1s 311us/step - loss: 0.0047 - val_loss: 0.0014\n",
      "Epoch 48/100\n",
      "4232/4232 [==============================] - 1s 314us/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 49/100\n",
      "4232/4232 [==============================] - 1s 311us/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 50/100\n",
      "4232/4232 [==============================] - 1s 309us/step - loss: 0.0048 - val_loss: 0.0016\n",
      "Epoch 51/100\n",
      "4232/4232 [==============================] - 1s 308us/step - loss: 0.0059 - val_loss: 7.4006e-04\n",
      "Epoch 52/100\n",
      "4232/4232 [==============================] - 1s 315us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 53/100\n",
      "4232/4232 [==============================] - 1s 315us/step - loss: 0.0053 - val_loss: 0.0021\n",
      "Epoch 54/100\n",
      "4232/4232 [==============================] - 1s 311us/step - loss: 0.0048 - val_loss: 0.0022\n",
      "Epoch 55/100\n",
      "4232/4232 [==============================] - 1s 312us/step - loss: 0.0054 - val_loss: 0.0014\n",
      "Epoch 56/100\n",
      "4232/4232 [==============================] - 1s 323us/step - loss: 0.0050 - val_loss: 0.0018\n",
      "Epoch 57/100\n",
      "4232/4232 [==============================] - 1s 313us/step - loss: 0.0048 - val_loss: 8.9184e-04\n",
      "Epoch 58/100\n",
      "4232/4232 [==============================] - 1s 314us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 59/100\n",
      "4232/4232 [==============================] - 1s 313us/step - loss: 0.0048 - val_loss: 6.5353e-04\n",
      "Epoch 60/100\n",
      "4232/4232 [==============================] - 1s 316us/step - loss: 0.0049 - val_loss: 0.0013\n",
      "Epoch 61/100\n",
      "4232/4232 [==============================] - 1s 309us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 62/100\n",
      "4232/4232 [==============================] - 1s 312us/step - loss: 0.0057 - val_loss: 8.8765e-04\n",
      "Epoch 63/100\n",
      "4232/4232 [==============================] - 1s 330us/step - loss: 0.0046 - val_loss: 0.0013\n",
      "Epoch 64/100\n",
      "4232/4232 [==============================] - 1s 310us/step - loss: 0.0043 - val_loss: 0.0057\n",
      "Epoch 65/100\n",
      "4232/4232 [==============================] - 1s 312us/step - loss: 0.0045 - val_loss: 6.6610e-04\n",
      "Epoch 66/100\n",
      "4232/4232 [==============================] - 1s 309us/step - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 67/100\n",
      "4232/4232 [==============================] - 1s 316us/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 68/100\n",
      "4232/4232 [==============================] - 1s 308us/step - loss: 0.0047 - val_loss: 8.5302e-04\n",
      "Epoch 69/100\n",
      "4232/4232 [==============================] - 1s 310us/step - loss: 0.0047 - val_loss: 9.6835e-04\n",
      "Epoch 70/100\n",
      "4232/4232 [==============================] - 1s 308us/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 71/100\n",
      "4232/4232 [==============================] - 1s 310us/step - loss: 0.0051 - val_loss: 2.3797e-04\n",
      "Epoch 72/100\n",
      "4232/4232 [==============================] - 1s 332us/step - loss: 0.0029 - val_loss: 6.4901e-04\n",
      "Epoch 73/100\n",
      "4232/4232 [==============================] - 1s 310us/step - loss: 0.0058 - val_loss: 3.8994e-04\n",
      "Epoch 74/100\n",
      "4232/4232 [==============================] - 1s 314us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 75/100\n",
      "4232/4232 [==============================] - 1s 314us/step - loss: 0.0043 - val_loss: 0.0010\n",
      "Epoch 76/100\n",
      "4232/4232 [==============================] - 1s 309us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4232/4232 [==============================] - 1s 311us/step - loss: 0.0056 - val_loss: 8.3362e-04\n",
      "Epoch 78/100\n",
      "4232/4232 [==============================] - 1s 311us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 79/100\n",
      "4232/4232 [==============================] - 1s 315us/step - loss: 0.0046 - val_loss: 0.0013\n",
      "Epoch 80/100\n",
      "4232/4232 [==============================] - 1s 316us/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 81/100\n",
      "4232/4232 [==============================] - 1s 314us/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 82/100\n",
      "4232/4232 [==============================] - 1s 316us/step - loss: 0.0045 - val_loss: 0.0020\n",
      "Epoch 83/100\n",
      "4232/4232 [==============================] - 1s 311us/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 84/100\n",
      "4232/4232 [==============================] - 1s 306us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 85/100\n",
      "4232/4232 [==============================] - 1s 309us/step - loss: 0.0042 - val_loss: 8.6839e-04\n",
      "Epoch 86/100\n",
      "4232/4232 [==============================] - 1s 311us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 87/100\n",
      "4232/4232 [==============================] - 1s 317us/step - loss: 0.0040 - val_loss: 3.0023e-04\n",
      "Epoch 88/100\n",
      "4232/4232 [==============================] - 1s 318us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 89/100\n",
      "4232/4232 [==============================] - 1s 307us/step - loss: 0.0035 - val_loss: 2.4539e-04\n",
      "Epoch 90/100\n",
      "4232/4232 [==============================] - 1s 311us/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 91/100\n",
      "4232/4232 [==============================] - 1s 309us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 92/100\n",
      "4232/4232 [==============================] - 1s 316us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 93/100\n",
      "4232/4232 [==============================] - 1s 320us/step - loss: 0.0036 - val_loss: 7.0243e-05\n",
      "Epoch 94/100\n",
      "4232/4232 [==============================] - 1s 320us/step - loss: 0.0031 - val_loss: 0.0057\n",
      "Epoch 95/100\n",
      "4232/4232 [==============================] - 1s 314us/step - loss: 0.0043 - val_loss: 1.8985e-04\n",
      "Epoch 96/100\n",
      "4232/4232 [==============================] - 1s 310us/step - loss: 0.0030 - val_loss: 0.0082\n",
      "Epoch 97/100\n",
      "4232/4232 [==============================] - 1s 320us/step - loss: 0.0040 - val_loss: 7.5676e-04\n",
      "Epoch 98/100\n",
      "4232/4232 [==============================] - 1s 312us/step - loss: 0.0041 - val_loss: 0.0016\n",
      "Epoch 99/100\n",
      "4232/4232 [==============================] - 1s 314us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 100/100\n",
      "4232/4232 [==============================] - 1s 312us/step - loss: 0.0042 - val_loss: 6.1787e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd203f5a7f0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs  = 100\n",
    "seq_len = 50\n",
    "path_data = 'sinwave.csv'\n",
    "\n",
    "print('> Loading data... ')\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(path_data, seq_len, True)\n",
    "\n",
    "print('> Data Loaded. Compiling...')\n",
    "\n",
    "model = build_model([1, 50, 100, 1])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    nb_epoch=epochs,\n",
    "    validation_split=0.05)\n",
    "\n",
    "#predicted = predict_point_by_point(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(predicted_data, true_data):\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    plt.plot(predicted_data, label='Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_results_multiple(predicted_data, true_data, prediction_len):\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    #Pad the list of predictions to shift it in the graph to it's correct start\n",
    "    for i, data in enumerate(predicted_data):\n",
    "        padding = [None for p in range(i * prediction_len)]\n",
    "        plt.plot(padding + data, label='Prediction')\n",
    "        plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
